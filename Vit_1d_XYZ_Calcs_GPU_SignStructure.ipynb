{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\"\n",
    "\n",
    "os.environ['NETKET_EXPERIMENTAL_SHARDING'] = '1'\n",
    "os.environ['NETKET_EXPERIMENTAL_FFT_AUTOCORRELATION'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here we run the different optimizations with sign structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netket as nk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append('/scratch/samiz/GPU_ViT_Calcs/models')\n",
    "sys.path.append('/scratch/samiz/GPU_ViT_Calcs/Logger_Pickle')\n",
    "\n",
    "from Afm_Model_functions import H_afm_1d as H_xyz_1d\n",
    "from ViT_1d_translation import *\n",
    "import ViT_1d_translation_Xavier as xavier\n",
    "from vmc_2spins_sampler import VMC_SR, grad_norms_callback\n",
    "\n",
    "from json_log import PickledJsonLog\n",
    "\n",
    "from scipy.sparse.linalg import eigsh\n",
    "\n",
    "from optax.schedules import linear_schedule\n",
    "from convergence_stopping import LateConvergenceStopping\n",
    "from netket.callbacks import InvalidLossStopping\n",
    "import pickle\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stopper1 = InvalidLossStopping(monitor = 'mean', patience = 20)\n",
    "Stopper2 = LateConvergenceStopping(target = 0.001, monitor = 'variance', patience = 20, start_from_step=100)\n",
    "\n",
    "log_curr = nk.logging.RuntimeLog()\n",
    "DataDir = '/scratch/samiz/GPU_ViT_Calcs/ViT_1d_Calcs/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16 Spins with Sign Structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_Ha16 = {\n",
    "    'L' : 16,\n",
    "    'J' : 1.0,\n",
    "    'Dxy' : 0.75,\n",
    "    'd' : 0.1,\n",
    "    'parity': 0.,\n",
    "    'make_rot' : True,\n",
    "    'exchange_XY' : True,\n",
    "    'return_hi' : True\n",
    "}\n",
    "\n",
    "Ha16, hi16 = H_xyz_1d(L = p_Ha16['L'], J1 = p_Ha16['J'], Dxy = p_Ha16['Dxy'], d = p_Ha16['d'], parity= p_Ha16['parity'], \n",
    "                            make_rotation = p_Ha16['make_rot'], exchange_XY = p_Ha16['exchange_XY'], return_space= p_Ha16['return_hi'])\n",
    "\n",
    "sampler_16 = nk.sampler.MetropolisHamiltonian(hilbert=hi16, hamiltonian=Ha16.to_jax_operator(), n_chains=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_opt_16 = {\n",
    "    # 'learning_rate' : linear_schedule(init_value=1e-3, end_value=1e-4, transition_steps=150, transition_begin=400),\n",
    "    'learning_rate': 1e-3,\n",
    "\n",
    "    # 'dshift' : 1e-4,\n",
    "    'dshift' : linear_schedule(init_value=1e-4, end_value=1e-5, transition_steps=100, transition_begin=300),\n",
    "\n",
    "    'n_iter' : 800,\n",
    "    'n_samples' : 2**12,\n",
    "    'chunk_size' : 2**10,\n",
    "    'holom' : True,\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "pvit_16 = {\n",
    "    'p' : 4,\n",
    "    'd' : 16,\n",
    "    'h' : 4,\n",
    "    'nl' : 1, \n",
    "}\n",
    "\n",
    "transl_arr = get_translations(number_nodes=p_Ha16['L'], patch_size=pvit_16['p'])\n",
    "pvit_16['translations'] = transl_arr\n",
    "\n",
    "# m_vit_64 = Simplified_ViT_TranslationSymmetric(patch_size=pvit_64['p'], embed_dim=pvit_64['d'], heads=pvit_64['h'], nl=pvit_64['nl'],\n",
    "                                                #  translations=pvit_64['translations'])\n",
    "\n",
    "m_vit_xavier_16 = xavier.Simplified_ViT_TranslationSymmetric(patch_size=pvit_16['p'], embed_dim=pvit_16['d'], heads=pvit_16['h'], nl=pvit_16['nl'],\n",
    "                                                 translations=pvit_16['translations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/samiz/GPU_ViT_Calcs/venv/lib/python3.11/site-packages/netket/hilbert/random/homogeneous.py:123: UnoptimisedCustomConstraintRandomStateMethodWarning: \n",
      "Defaulting to a slow, possibly infinitely-looping method to generate random state of\n",
      "the current Hilbert space with a custom constraint. Consider implementing a\n",
      "custom `random_state` method for your constraint if this method takes a long time to\n",
      "generate a random state.\n",
      "\n",
      "================================================================\n",
      "You can silence this warning by setting the environment variable\n",
      "``NETKET_RANDOM_STATE_FALLBACK_WARNING=0``\n",
      "or by setting ``nk.config.netket_random_state_fallback_warning = False``\n",
      "in your code.\n",
      "================================================================\n",
      "\n",
      "To generate a custom random_state dispatched method, you should use multiple dispatch\n",
      "following the following syntax:\n",
      "\n",
      ">>> import netket as nk\n",
      ">>> from netket.utils import dispatch\n",
      ">>>\n",
      ">>> @dispatch.dispatch\n",
      ">>> def random_state(hilb: netket.hilbert.spin.Spin,\n",
      "                    constraint: vmc_2spins_sampler.Mtot_Parity_Constraint,\n",
      "                    key,\n",
      "                    batches: int,\n",
      "                    *,\n",
      "                    dtype=None):\n",
      ">>>    # your custom implementation here\n",
      ">>>    # You should return a batch of `batches` random states, with the given dtype.\n",
      ">>>    # return jax.Array with shape (batches, hilb.size) and dtype dtype.\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "For more detailed informations, visit the following link:\n",
      "\t https://netket.readthedocs.io/en/latest/api/_generated/errors/netket.errors.UnoptimisedCustomConstraintRandomStateMethodWarning.html\n",
      "or the list of all common errors and warnings at\n",
      "\t https://netket.readthedocs.io/en/latest/api/errors.html\n",
      "-------------------------------------------------------\n",
      "\n",
      "  warnings.warn(\n",
      "/scratch/samiz/GPU_ViT_Calcs/venv/lib/python3.11/site-packages/netket/hilbert/random/homogeneous.py:123: UnoptimisedCustomConstraintRandomStateMethodWarning: \n",
      "Defaulting to a slow, possibly infinitely-looping method to generate random state of\n",
      "the current Hilbert space with a custom constraint. Consider implementing a\n",
      "custom `random_state` method for your constraint if this method takes a long time to\n",
      "generate a random state.\n",
      "\n",
      "================================================================\n",
      "You can silence this warning by setting the environment variable\n",
      "``NETKET_RANDOM_STATE_FALLBACK_WARNING=0``\n",
      "or by setting ``nk.config.netket_random_state_fallback_warning = False``\n",
      "in your code.\n",
      "================================================================\n",
      "\n",
      "To generate a custom random_state dispatched method, you should use multiple dispatch\n",
      "following the following syntax:\n",
      "\n",
      ">>> import netket as nk\n",
      ">>> from netket.utils import dispatch\n",
      ">>>\n",
      ">>> @dispatch.dispatch\n",
      ">>> def random_state(hilb: netket.hilbert.spin.Spin,\n",
      "                    constraint: vmc_2spins_sampler.Mtot_Parity_Constraint,\n",
      "                    key,\n",
      "                    batches: int,\n",
      "                    *,\n",
      "                    dtype=None):\n",
      ">>>    # your custom implementation here\n",
      ">>>    # You should return a batch of `batches` random states, with the given dtype.\n",
      ">>>    # return jax.Array with shape (batches, hilb.size) and dtype dtype.\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "For more detailed informations, visit the following link:\n",
      "\t https://netket.readthedocs.io/en/latest/api/_generated/errors/netket.errors.UnoptimisedCustomConstraintRandomStateMethodWarning.html\n",
      "or the list of all common errors and warnings at\n",
      "\t https://netket.readthedocs.io/en/latest/api/errors.html\n",
      "-------------------------------------------------------\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters:  352\n",
      "using regular SR\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aae8a589a3b4b71aa464d6260fa1207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/samiz/GPU_ViT_Calcs/venv/lib/python3.11/site-packages/jax/_src/lax/lax.py:3373: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  x_bar = _convert_element_type(x_bar, x.aval.dtype, x.aval.weak_type)\n"
     ]
    }
   ],
   "source": [
    "nls = [1]\n",
    "\n",
    "for j, nl in enumerate(nls):\n",
    "    m_vit_16 = Simplified_ViT_TranslationSymmetric(patch_size=pvit_16['p'], embed_dim=pvit_16['d'], heads=pvit_16['h'], nl=nl,\n",
    "                                                     translations=pvit_16['translations'])\n",
    "\n",
    "\n",
    "    gs, vs = VMC_SR(hamiltonian=Ha16.to_jax_operator(), sampler=sampler_16, model = m_vit_16, learning_rate=p_opt_16['learning_rate'], diag_shift=p_opt_16['dshift'],\n",
    "                n_samples=p_opt_16['n_samples'], chunk_size=p_opt_16['chunk_size'], holomorph=p_opt_16['holom'], discards=8)\n",
    "\n",
    "    StateLogger64 = PickledJsonLog(output_prefix=DataDir + 'log_vit_16S_Sign_nl_{}_transl'.format(nl), save_params_every=10, save_params=True)\n",
    "\n",
    "    gs.run(out=(log_curr, StateLogger64), n_iter=p_opt_16['n_iter'], callback=[grad_norms_callback, Stopper1, Stopper2])\n",
    "\n",
    "    log_curr.serialize(DataDir + 'log_vit_16S_Sign_nl_{}_transl'.format(nl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters:  352\n",
      "using regular SR\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "883f10bad3af4fa9a1728fc22a6d2af4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for j, nl in enumerate(nls):\n",
    "    m_vit_16 = Simplified_ViT(patch_size=pvit_16['p'], embed_dim=pvit_16['d'], heads=pvit_16['h'], nl=nl)\n",
    "\n",
    "\n",
    "    gs, vs = VMC_SR(hamiltonian=Ha16.to_jax_operator(), sampler=sampler_16, model = m_vit_16, learning_rate=p_opt_16['learning_rate'], diag_shift=p_opt_16['dshift'],\n",
    "                n_samples=p_opt_16['n_samples'], chunk_size=p_opt_16['chunk_size'], holomorph=p_opt_16['holom'], discards=8)\n",
    "\n",
    "    StateLogger64 = PickledJsonLog(output_prefix=DataDir + 'log_vit_16S_Sign_nl_{}'.format(nl), save_params_every=10, save_params=True)\n",
    "\n",
    "    gs.run(out=(log_curr, StateLogger64), n_iter=p_opt_16['n_iter'], callback=[grad_norms_callback, Stopper1, Stopper2])\n",
    "\n",
    "    # log_curr.serialize(DataDir + 'log_vit_16S_Sign_nl_{}'.format(nl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Now for 64 Spins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_Ha64 = {\n",
    "    'L' : 64,\n",
    "    'J' : 1.0,\n",
    "    'Dxy' : 0.75,\n",
    "    'd' : 0.1,\n",
    "    'parity': 0.,\n",
    "    'make_rot' : True,\n",
    "    'exchange_XY' : True,\n",
    "    'return_hi' : True\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "Ha64, hi64 = H_xyz_1d(L = p_Ha64['L'], J1 = p_Ha64['J'], Dxy = p_Ha64['Dxy'], d = p_Ha64['d'], parity= p_Ha64['parity'], \n",
    "                            make_rotation = p_Ha64['make_rot'], exchange_XY = p_Ha64['exchange_XY'], return_space= p_Ha64['return_hi'])\n",
    "\n",
    "sampler_64 = nk.sampler.MetropolisHamiltonian(hilbert=hi64, hamiltonian=Ha64.to_jax_operator(), n_chains=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_opt_64 = {\n",
    "    # 'learning_rate' : linear_schedule(init_value=1e-3, end_value=1e-4, transition_steps=200, transition_begin=500),\n",
    "    'learning_rate': 1e-3,\n",
    "    # 'dshift' : 1e-4,\n",
    "    'dshift': linear_schedule(init_value=1e-4, end_value=1e-5, transition_steps=100, transition_begin=300),\n",
    "    'n_iter' : 800,\n",
    "    'n_samples' : 2**12,\n",
    "    'chunk_size' : 2**10,\n",
    "    'holom' : True,\n",
    "\n",
    "}\n",
    "\n",
    "pvit_64 = {\n",
    "    'p' : 4,\n",
    "    'd' : 32,\n",
    "    'h' : 8,\n",
    "    'nl' : 1, \n",
    "}\n",
    "\n",
    "transl_arr = get_translations(number_nodes=p_Ha64['L'], patch_size=pvit_64['p'])\n",
    "pvit_64['translations'] = transl_arr\n",
    "\n",
    "# m_vit_64 = Simplified_ViT_TranslationSymmetric(patch_size=pvit_64['p'], embed_dim=pvit_64['d'], heads=pvit_64['h'], nl=pvit_64['nl'],\n",
    "                                                #  translations=pvit_64['translations'])\n",
    "\n",
    "m_vit_xavier_64 = xavier.Simplified_ViT_TranslationSymmetric(patch_size=pvit_64['p'], embed_dim=pvit_64['d'], heads=pvit_16['h'], nl=pvit_64['nl'],\n",
    "                                                 translations=pvit_64['translations'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/samiz/GPU_ViT_Calcs/venv/lib/python3.11/site-packages/netket/hilbert/random/homogeneous.py:123: UnoptimisedCustomConstraintRandomStateMethodWarning: \n",
      "Defaulting to a slow, possibly infinitely-looping method to generate random state of\n",
      "the current Hilbert space with a custom constraint. Consider implementing a\n",
      "custom `random_state` method for your constraint if this method takes a long time to\n",
      "generate a random state.\n",
      "\n",
      "================================================================\n",
      "You can silence this warning by setting the environment variable\n",
      "``NETKET_RANDOM_STATE_FALLBACK_WARNING=0``\n",
      "or by setting ``nk.config.netket_random_state_fallback_warning = False``\n",
      "in your code.\n",
      "================================================================\n",
      "\n",
      "To generate a custom random_state dispatched method, you should use multiple dispatch\n",
      "following the following syntax:\n",
      "\n",
      ">>> import netket as nk\n",
      ">>> from netket.utils import dispatch\n",
      ">>>\n",
      ">>> @dispatch.dispatch\n",
      ">>> def random_state(hilb: netket.hilbert.spin.Spin,\n",
      "                    constraint: vmc_2spins_sampler.Mtot_Parity_Constraint,\n",
      "                    key,\n",
      "                    batches: int,\n",
      "                    *,\n",
      "                    dtype=None):\n",
      ">>>    # your custom implementation here\n",
      ">>>    # You should return a batch of `batches` random states, with the given dtype.\n",
      ">>>    # return jax.Array with shape (batches, hilb.size) and dtype dtype.\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "For more detailed informations, visit the following link:\n",
      "\t https://netket.readthedocs.io/en/latest/api/_generated/errors/netket.errors.UnoptimisedCustomConstraintRandomStateMethodWarning.html\n",
      "or the list of all common errors and warnings at\n",
      "\t https://netket.readthedocs.io/en/latest/api/errors.html\n",
      "-------------------------------------------------------\n",
      "\n",
      "  warnings.warn(\n",
      "/scratch/samiz/GPU_ViT_Calcs/venv/lib/python3.11/site-packages/netket/hilbert/random/homogeneous.py:123: UnoptimisedCustomConstraintRandomStateMethodWarning: \n",
      "Defaulting to a slow, possibly infinitely-looping method to generate random state of\n",
      "the current Hilbert space with a custom constraint. Consider implementing a\n",
      "custom `random_state` method for your constraint if this method takes a long time to\n",
      "generate a random state.\n",
      "\n",
      "================================================================\n",
      "You can silence this warning by setting the environment variable\n",
      "``NETKET_RANDOM_STATE_FALLBACK_WARNING=0``\n",
      "or by setting ``nk.config.netket_random_state_fallback_warning = False``\n",
      "in your code.\n",
      "================================================================\n",
      "\n",
      "To generate a custom random_state dispatched method, you should use multiple dispatch\n",
      "following the following syntax:\n",
      "\n",
      ">>> import netket as nk\n",
      ">>> from netket.utils import dispatch\n",
      ">>>\n",
      ">>> @dispatch.dispatch\n",
      ">>> def random_state(hilb: netket.hilbert.spin.Spin,\n",
      "                    constraint: vmc_2spins_sampler.Mtot_Parity_Constraint,\n",
      "                    key,\n",
      "                    batches: int,\n",
      "                    *,\n",
      "                    dtype=None):\n",
      ">>>    # your custom implementation here\n",
      ">>>    # You should return a batch of `batches` random states, with the given dtype.\n",
      ">>>    # return jax.Array with shape (batches, hilb.size) and dtype dtype.\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "For more detailed informations, visit the following link:\n",
      "\t https://netket.readthedocs.io/en/latest/api/_generated/errors/netket.errors.UnoptimisedCustomConstraintRandomStateMethodWarning.html\n",
      "or the list of all common errors and warnings at\n",
      "\t https://netket.readthedocs.io/en/latest/api/errors.html\n",
      "-------------------------------------------------------\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters:  1312\n",
      "using regular SR\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60cd133af49b44dd88fd43e47cdee5e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/samiz/GPU_ViT_Calcs/venv/lib/python3.11/site-packages/jax/_src/lax/lax.py:3373: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  x_bar = _convert_element_type(x_bar, x.aval.dtype, x.aval.weak_type)\n"
     ]
    }
   ],
   "source": [
    "nls = [1]\n",
    "\n",
    "for j, nl in enumerate(nls):\n",
    "    m_vit_64 = Simplified_ViT_TranslationSymmetric(patch_size=pvit_64['p'], embed_dim=pvit_64['d'], heads=pvit_64['h'], nl=nl,\n",
    "                                                     translations=pvit_64['translations'])\n",
    "\n",
    "\n",
    "    gs, vs = VMC_SR(hamiltonian=Ha64.to_jax_operator(), sampler=sampler_64, model = m_vit_64, learning_rate=p_opt_64['learning_rate'], diag_shift=p_opt_64['dshift'],\n",
    "                n_samples=p_opt_64['n_samples'], chunk_size=p_opt_64['chunk_size'], holomorph=p_opt_64['holom'], discards=8)\n",
    "\n",
    "    StateLogger64 = PickledJsonLog(output_prefix=DataDir + 'log_vit_64S_Sign_nl_{}transl'.format(nl), save_params_every=10, save_params=True)\n",
    "\n",
    "    gs.run(out=(log_curr, StateLogger64), n_iter=p_opt_64['n_iter'], callback=[grad_norms_callback, Stopper1, Stopper2])\n",
    "\n",
    "    # log_curr.serialize(DataDir + 'log_vit_64S_Sign_nl_{}_transl'.format(nl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters:  1312\n",
      "using regular SR\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39c8d113174646c7a0ef7a5536c3b592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nls = [1]\n",
    "\n",
    "for j, nl in enumerate(nls):\n",
    "    m_vit_64 = Simplified_ViT(patch_size=pvit_64['p'], embed_dim=pvit_64['d'], heads=pvit_64['h'], nl=nl)\n",
    "                                                     \n",
    "\n",
    "\n",
    "    gs, vs = VMC_SR(hamiltonian=Ha64.to_jax_operator(), sampler=sampler_64, model = m_vit_64, learning_rate=p_opt_64['learning_rate'], diag_shift=p_opt_64['dshift'],\n",
    "                n_samples=p_opt_64['n_samples'], chunk_size=p_opt_64['chunk_size'], holomorph=p_opt_64['holom'], discards=8)\n",
    "\n",
    "    StateLogger64 = PickledJsonLog(output_prefix=DataDir + 'log_vit_64S_Sign_nl_{}'.format(nl), save_params_every=10, save_params=True)\n",
    "\n",
    "    gs.run(out=(log_curr, StateLogger64), n_iter=500, callback=[grad_norms_callback, Stopper1, Stopper2])\n",
    "\n",
    "    # log_curr.serialize(DataDir + 'log_vit_64S_Sign_nl_{}'.format(nl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now for 100 Spins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_Ha = {\n",
    "    'L' : 100,\n",
    "    'J' : 1.0,\n",
    "    'Dxy' : 0.75,\n",
    "    'd' : 0.1,\n",
    "    'parity': 0.,\n",
    "    'make_rot' : True,\n",
    "    'exchange_XY' : True,\n",
    "    'return_hi' : True\n",
    "}\n",
    "\n",
    "Ha100, hi100 = H_xyz_1d(L = p_Ha['L'], J1 = p_Ha['J'], Dxy = p_Ha['Dxy'], d = p_Ha['d'], parity= p_Ha['parity'], \n",
    "                            make_rotation = p_Ha['make_rot'], exchange_XY = p_Ha['exchange_XY'], return_space= p_Ha['return_hi'])\n",
    "\n",
    "sampler_100 = nk.sampler.MetropolisHamiltonian(hilbert=hi100, hamiltonian=Ha100.to_jax_operator(), n_chains=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvit_100_Vers1 = {\n",
    "    'p' : 4,\n",
    "    'd' : 32,\n",
    "    'h' : 8,\n",
    "    'nl' : 1, \n",
    "}\n",
    "\n",
    "transl_arr = get_translations(number_nodes=100, patch_size=pvit_100_Vers1['p'])\n",
    "pvit_100_Vers1['translations'] = transl_arr\n",
    "\n",
    "m_vit_100 = Simplified_ViT_TranslationSymmetric(patch_size=pvit_100_Vers1['p'], embed_dim=pvit_100_Vers1['d'], heads=pvit_100_Vers1['h'], nl=pvit_100_Vers1['nl'],\n",
    "                                                 translations=pvit_100_Vers1['translations'])\n",
    "\n",
    "m_vit_xavier = xavier.Simplified_ViT_TranslationSymmetric(patch_size=pvit_100_Vers1['p'], embed_dim=pvit_100_Vers1['d'], heads=pvit_100_Vers1['h'], nl=pvit_100_Vers1['nl'],\n",
    "                                                 translations=pvit_100_Vers1['translations'])\n",
    "\n",
    "# vs_vit100_trasl = nk.vqs.MCState(sampler=sampler_100, model=m_vit_100, n_samples=2**10)\n",
    "vs_vit100_trasl = nk.vqs.MCState(sampler=sampler_100, model=m_vit_xavier, n_samples=2**10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_opt_100 = {\n",
    "    # 'learning_rate' : linear_schedule(init_value=1e-3, end_value=1e-4, transition_steps=200, transition_begin=500),\n",
    "    'learning_rate': linear_schedule(init_value=1e-3, end_value=1e-4, transition_steps=100, transition_begin=400),\n",
    "    # 'dshift' : 1e-4,\n",
    "    'dshift': linear_schedule(init_value=1e-4, end_value=1e-5, transition_steps=100, transition_begin=300),\n",
    "    'n_iter' : 800,\n",
    "    'n_samples' : 2**12,\n",
    "    'chunk_size' : 2**10,\n",
    "    'holom' : True,\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters:  1384\n",
      "using regular SR\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60d447f758224ae48971a77732226657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nls = [1]\n",
    "\n",
    "for j, nl in enumerate(nls):\n",
    "    m_vit_100 = Simplified_ViT_TranslationSymmetric(patch_size=pvit_100_Vers1['p'], embed_dim=pvit_100_Vers1['d'], heads=pvit_100_Vers1['h'], nl=nl,\n",
    "                                                     translations=pvit_100_Vers1['translations'])\n",
    "\n",
    "\n",
    "    gs, vs = VMC_SR(hamiltonian=Ha100.to_jax_operator(), sampler=sampler_100, model = m_vit_100, learning_rate=p_opt_100['learning_rate'], diag_shift=p_opt_100['dshift'],\n",
    "                n_samples=p_opt_100['n_samples'], chunk_size=p_opt_100['chunk_size'], holomorph=p_opt_100['holom'], discards=8)\n",
    "\n",
    "    StateLogger = PickledJsonLog(output_prefix=DataDir + 'log_vit_100S_Sign_nl_{}_p{}_d{}_transl'.format(nl, pvit_100_Vers1['p'], pvit_100_Vers1['d']), save_params_every=10, save_params=True)\n",
    "\n",
    "    gs.run(out=(log_curr, StateLogger), n_iter=p_opt_100['n_iter'], callback=[grad_norms_callback, Stopper1, Stopper2])\n",
    "\n",
    "    log_curr.serialize(DataDir + 'log_vit_100S_Sign_nl_{}_p{}_d{}_transl'.format(nl, pvit_100_Vers1['p'], pvit_100_Vers1['d']))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvit_100_Vers2 = {\n",
    "    'p' : 10,\n",
    "    'd' : 32,\n",
    "    'h' : 8,\n",
    "    'nl' : 1, \n",
    "}\n",
    "\n",
    "transl_arr = get_translations(number_nodes=100, patch_size=pvit_100_Vers2['p'])\n",
    "pvit_100_Vers2['translations'] = transl_arr\n",
    "\n",
    "m_vit_100 = Simplified_ViT_TranslationSymmetric(patch_size=pvit_100_Vers2['p'], embed_dim=pvit_100_Vers2['d'], heads=pvit_100_Vers2['h'], nl=pvit_100_Vers2['nl'],\n",
    "                                                 translations=pvit_100_Vers2['translations'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/samiz/GPU_ViT_Calcs/venv/lib/python3.11/site-packages/netket/hilbert/random/homogeneous.py:123: UnoptimisedCustomConstraintRandomStateMethodWarning: \n",
      "Defaulting to a slow, possibly infinitely-looping method to generate random state of\n",
      "the current Hilbert space with a custom constraint. Consider implementing a\n",
      "custom `random_state` method for your constraint if this method takes a long time to\n",
      "generate a random state.\n",
      "\n",
      "================================================================\n",
      "You can silence this warning by setting the environment variable\n",
      "``NETKET_RANDOM_STATE_FALLBACK_WARNING=0``\n",
      "or by setting ``nk.config.netket_random_state_fallback_warning = False``\n",
      "in your code.\n",
      "================================================================\n",
      "\n",
      "To generate a custom random_state dispatched method, you should use multiple dispatch\n",
      "following the following syntax:\n",
      "\n",
      ">>> import netket as nk\n",
      ">>> from netket.utils import dispatch\n",
      ">>>\n",
      ">>> @dispatch.dispatch\n",
      ">>> def random_state(hilb: netket.hilbert.spin.Spin,\n",
      "                    constraint: vmc_2spins_sampler.Mtot_Parity_Constraint,\n",
      "                    key,\n",
      "                    batches: int,\n",
      "                    *,\n",
      "                    dtype=None):\n",
      ">>>    # your custom implementation here\n",
      ">>>    # You should return a batch of `batches` random states, with the given dtype.\n",
      ">>>    # return jax.Array with shape (batches, hilb.size) and dtype dtype.\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "For more detailed informations, visit the following link:\n",
      "\t https://netket.readthedocs.io/en/latest/api/_generated/errors/netket.errors.UnoptimisedCustomConstraintRandomStateMethodWarning.html\n",
      "or the list of all common errors and warnings at\n",
      "\t https://netket.readthedocs.io/en/latest/api/errors.html\n",
      "-------------------------------------------------------\n",
      "\n",
      "  warnings.warn(\n",
      "/scratch/samiz/GPU_ViT_Calcs/venv/lib/python3.11/site-packages/netket/hilbert/random/homogeneous.py:123: UnoptimisedCustomConstraintRandomStateMethodWarning: \n",
      "Defaulting to a slow, possibly infinitely-looping method to generate random state of\n",
      "the current Hilbert space with a custom constraint. Consider implementing a\n",
      "custom `random_state` method for your constraint if this method takes a long time to\n",
      "generate a random state.\n",
      "\n",
      "================================================================\n",
      "You can silence this warning by setting the environment variable\n",
      "``NETKET_RANDOM_STATE_FALLBACK_WARNING=0``\n",
      "or by setting ``nk.config.netket_random_state_fallback_warning = False``\n",
      "in your code.\n",
      "================================================================\n",
      "\n",
      "To generate a custom random_state dispatched method, you should use multiple dispatch\n",
      "following the following syntax:\n",
      "\n",
      ">>> import netket as nk\n",
      ">>> from netket.utils import dispatch\n",
      ">>>\n",
      ">>> @dispatch.dispatch\n",
      ">>> def random_state(hilb: netket.hilbert.spin.Spin,\n",
      "                    constraint: vmc_2spins_sampler.Mtot_Parity_Constraint,\n",
      "                    key,\n",
      "                    batches: int,\n",
      "                    *,\n",
      "                    dtype=None):\n",
      ">>>    # your custom implementation here\n",
      ">>>    # You should return a batch of `batches` random states, with the given dtype.\n",
      ">>>    # return jax.Array with shape (batches, hilb.size) and dtype dtype.\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "For more detailed informations, visit the following link:\n",
      "\t https://netket.readthedocs.io/en/latest/api/_generated/errors/netket.errors.UnoptimisedCustomConstraintRandomStateMethodWarning.html\n",
      "or the list of all common errors and warnings at\n",
      "\t https://netket.readthedocs.io/en/latest/api/errors.html\n",
      "-------------------------------------------------------\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters:  1456\n",
      "using regular SR\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34ef9b1317a34e269e803c49e8455c9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/samiz/GPU_ViT_Calcs/venv/lib/python3.11/site-packages/jax/_src/lax/lax.py:3373: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  x_bar = _convert_element_type(x_bar, x.aval.dtype, x.aval.weak_type)\n"
     ]
    }
   ],
   "source": [
    "nls = [1]\n",
    "\n",
    "for j, nl in enumerate(nls):\n",
    "    m_vit_100 = Simplified_ViT_TranslationSymmetric(patch_size=pvit_100_Vers2['p'], embed_dim=pvit_100_Vers2['d'], heads=pvit_100_Vers2['h'], nl=nl,\n",
    "                                                     translations=pvit_100_Vers2['translations'])\n",
    "\n",
    "\n",
    "    gs, vs = VMC_SR(hamiltonian=Ha100.to_jax_operator(), sampler=sampler_100, model = m_vit_100, learning_rate=p_opt_100['learning_rate'], diag_shift=p_opt_100['dshift'],\n",
    "                n_samples=p_opt_100['n_samples'], chunk_size=p_opt_100['chunk_size'], holomorph=p_opt_100['holom'], discards=8)\n",
    "\n",
    "    StateLogger = PickledJsonLog(output_prefix=DataDir + 'log_vit_100S_Sign_nl_{}_p{}_d{}_transl'.format(nl, pvit_100_Vers2['p'], pvit_100_Vers2['d']), save_params_every=10, save_params=True)\n",
    "\n",
    "    gs.run(out=(log_curr, StateLogger), n_iter=p_opt_100['n_iter'], callback=[grad_norms_callback, Stopper1, Stopper2])\n",
    "\n",
    "    # log_curr.serialize(DataDir + 'log_vit_100S_Sign_nl_{}_p{}_d{}_transl'.format(nl, pvit_100_Vers1['p'], pvit_100_Vers1['d']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nls = [1]\n",
    "\n",
    "# for j, nl in enumerate(nls):\n",
    "#     m_vit_100 = Simplified_ViT(patch_size=pvit_100_Vers2['p'], embed_dim=pvit_100_Vers2['d'], heads=pvit_100_Vers2['h'], nl=nl)\n",
    "                                                     \n",
    "\n",
    "\n",
    "#     gs, vs = VMC_SR(hamiltonian=Ha100.to_jax_operator(), sampler=sampler_100, model = m_vit_100, learning_rate=p_opt_100['learning_rate'], diag_shift=p_opt_100['dshift'],\n",
    "#                 n_samples=p_opt_100['n_samples'], chunk_size=p_opt_100['chunk_size'], holomorph=p_opt_100['holom'], discards=8)\n",
    "\n",
    "#     StateLogger = PickledJsonLog(output_prefix=DataDir + 'log_vit_100S_Sign_nl_{}_p{}_d{}'.format(nl, pvit_100_Vers2['p'], pvit_100_Vers2['d']), save_params_every=10, save_params=True)\n",
    "\n",
    "#     gs.run(out=(log_curr, StateLogger), n_iter=p_opt_100['n_iter'], callback=[grad_norms_callback, Stopper1, Stopper2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
